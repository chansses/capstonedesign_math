import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report
from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings('ignore')

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False

class ThresholdDetectionModel:
    """
    ê¸°ì¤€ì„  ì´ˆê³¼ íƒì§€ ëª¨ë¸
    - ëª©ì : ë‹¤ìŒ ì‹œì ì— ê¸°ì¤€ì„ ì„ ë„˜ì„ì§€ ë¯¸ë¦¬ ì˜ˆì¸¡
    - íŠ¹ì§•: ì˜¨ë„, CO2, ë³€í™”ìœ¨, ì¶”ì„¸ ë“± í™œìš©
    """
    
    def __init__(self, temp_threshold=26.0, co2_threshold=1000.0):
        """
        ëª¨ë¸ ì´ˆê¸°í™”
        
        Parameters:
        -----------
        temp_threshold : float
            ì˜¨ë„ ê¸°ì¤€ì„ 
        co2_threshold : float
            CO2 ê¸°ì¤€ì„ 
        
        Note:
        -----
        High ìƒíƒœ ì •ì˜: ì˜¨ë„ > temp_threshold AND CO2 > co2_threshold (ë‘˜ ë‹¤ ë„˜ì–´ì•¼ High)
        """
        self.temp_threshold = temp_threshold
        self.co2_threshold = co2_threshold
        self.model = None
        self.scaler = StandardScaler()
        
    def prepare_features(self, df, window_size=3):
        """
        íŠ¹ì§• ì¤€ë¹„
        
        Parameters:
        -----------
        df : pandas.DataFrame
            ë°ì´í„°í”„ë ˆì„
        window_size : int
            ìœˆë„ìš° í¬ê¸° (ìµœê·¼ Nê°œ ì‹œì  ê³ ë ¤)
            
        Returns:
        --------
        X : np.array
            íŠ¹ì§• í–‰ë ¬
        y : np.array
            íƒ€ê²Ÿ (ë‹¤ìŒ ì‹œì ì— High ìƒíƒœì¸ì§€: 1=High, 0=Normal)
        """
        features_list = []
        targets = []
        
        for i in range(window_size, len(df) - 1):
            # í˜„ì¬ ì‹œì ì˜ íŠ¹ì§•
            current_temp = df.iloc[i]['Temp_avg']
            current_co2 = df.iloc[i]['S5_CO2']
            current_temp_diff = df.iloc[i]['Temp_diff']
            current_co2_slope = df.iloc[i]['CO2_Slope']
            current_occupancy = df.iloc[i]['Room_Occupancy_Count']
            
            # ìµœê·¼ ìœˆë„ìš°ì˜ í‰ê· ê³¼ ì¶”ì„¸
            window_temp = df.iloc[i-window_size:i+1]['Temp_avg'].values
            window_co2 = df.iloc[i-window_size:i+1]['S5_CO2'].values
            
            # ê¸°ì¤€ì„ ê¹Œì§€ì˜ ê±°ë¦¬
            distance_to_temp_threshold = current_temp - self.temp_threshold
            distance_to_co2_threshold = current_co2 - self.co2_threshold
            
            # ì¶”ì„¸ (ìµœê·¼ Nê°œ ì‹œì ì˜ ë³€í™”ìœ¨)
            temp_trend = np.mean(np.diff(window_temp)) if len(window_temp) > 1 else 0
            co2_trend = np.mean(np.diff(window_co2)) if len(window_co2) > 1 else 0
            
            # ìµœê·¼ í‰ê· 
            temp_avg_recent = np.mean(window_temp)
            co2_avg_recent = np.mean(window_co2)
            
            # íŠ¹ì§• ë²¡í„°
            features = [
                current_temp,
                current_co2,
                current_temp_diff,
                current_co2_slope,
                current_occupancy,
                distance_to_temp_threshold,
                distance_to_co2_threshold,
                temp_trend,
                co2_trend,
                temp_avg_recent,
                co2_avg_recent,
                # ê¸°ì¤€ì„  ì´ˆê³¼ ì—¬ë¶€
                1 if current_temp > self.temp_threshold else 0,
                1 if current_co2 > self.co2_threshold else 0,
            ]
            
            features_list.append(features)
            
            # íƒ€ê²Ÿ: ë‹¤ìŒ ì‹œì ì´ High ìƒíƒœì¸ì§€ (AND ì¡°ê±´: ë‘˜ ë‹¤ ë„˜ì–´ì•¼ High)
            next_temp = df.iloc[i+1]['Temp_avg']
            next_co2 = df.iloc[i+1]['S5_CO2']
            is_high = 1 if (next_temp > self.temp_threshold and next_co2 > self.co2_threshold) else 0
            targets.append(is_high)
        
        return np.array(features_list), np.array(targets)
    
    def fit(self, df, window_size=3, test_size=0.2, random_state=42):
        """
        ëª¨ë¸ í•™ìŠµ
        
        Parameters:
        -----------
        df : pandas.DataFrame
            í•™ìŠµ ë°ì´í„°
        window_size : int
            ìœˆë„ìš° í¬ê¸°
        test_size : float
            í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¹„ìœ¨
        random_state : int
            ëœë¤ ì‹œë“œ
        """
        print("ğŸ”„ íŠ¹ì§• ì¤€ë¹„ ì¤‘...")
        X, y = self.prepare_features(df, window_size)
        print(f"âœ… íŠ¹ì§• ì¤€ë¹„ ì™„ë£Œ: {X.shape[0]}ê°œ ìƒ˜í”Œ, {X.shape[1]}ê°œ íŠ¹ì§•")
        print(f"ğŸ“Š íƒ€ê²Ÿ ë¶„í¬: High={np.sum(y)}ê°œ ({np.sum(y)/len(y)*100:.2f}%), Normal={len(y)-np.sum(y)}ê°œ")
        
        # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í• 
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=random_state, stratify=y
        )
        
        # ì •ê·œí™”
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)
        
        # Random Forest ëª¨ë¸ í•™ìŠµ
        print("\nğŸŒ² Random Forest ëª¨ë¸ í•™ìŠµ ì¤‘...")
        self.model = RandomForestClassifier(
            n_estimators=100,
            max_depth=10,
            min_samples_split=5,
            min_samples_leaf=2,
            class_weight='balanced',  # í´ë˜ìŠ¤ ë¶ˆê· í˜• í•´ê²°
            random_state=random_state,
            n_jobs=-1
        )
        
        self.model.fit(X_train_scaled, y_train)
        
        # í•™ìŠµ ì„±ëŠ¥ í‰ê°€
        train_pred = self.model.predict(X_train_scaled)
        train_acc = accuracy_score(y_train, train_pred)
        train_f1 = f1_score(y_train, train_pred)
        
        print(f"âœ… í•™ìŠµ ì™„ë£Œ!")
        print(f"   í•™ìŠµ ì •í™•ë„: {train_acc:.4f} ({train_acc*100:.2f}%)")
        print(f"   í•™ìŠµ F1-Score: {train_f1:.4f} ({train_f1*100:.2f}%)")
        
        # í…ŒìŠ¤íŠ¸ ì„±ëŠ¥ í‰ê°€
        test_pred = self.model.predict(X_test_scaled)
        test_acc = accuracy_score(y_test, test_pred)
        test_precision = precision_score(y_test, test_pred, zero_division=0)
        test_recall = recall_score(y_test, test_pred, zero_division=0)
        test_f1 = f1_score(y_test, test_pred, zero_division=0)
        
        print(f"\nğŸ“Š í…ŒìŠ¤íŠ¸ ì„±ëŠ¥:")
        print(f"   ì •í™•ë„: {test_acc:.4f} ({test_acc*100:.2f}%)")
        print(f"   Precision: {test_precision:.4f} ({test_precision*100:.2f}%)")
        print(f"   Recall: {test_recall:.4f} ({test_recall*100:.2f}%)")
        print(f"   F1-Score: {test_f1:.4f} ({test_f1*100:.2f}%)")
        
        # í˜¼ë™ í–‰ë ¬
        cm = confusion_matrix(y_test, test_pred)
        print(f"\nğŸ“Š í˜¼ë™ í–‰ë ¬:")
        print(f"   ì‹¤ì œ\\ì˜ˆì¸¡  Normal  High")
        print(f"   Normal      {cm[0,0]:4d}   {cm[0,1]:4d}")
        print(f"   High        {cm[1,0]:4d}   {cm[1,1]:4d}")
        
        # íŠ¹ì§• ì¤‘ìš”ë„
        feature_names = [
            'Temp_avg', 'S5_CO2', 'Temp_diff', 'CO2_Slope', 'Occupancy',
            'Dist_to_Temp_Thresh', 'Dist_to_CO2_Thresh',
            'Temp_Trend', 'CO2_Trend',
            'Temp_Avg_Recent', 'CO2_Avg_Recent',
            'Temp_Exceed', 'CO2_Exceed'
        ]
        
        importances = self.model.feature_importances_
        feature_importance = list(zip(feature_names, importances))
        feature_importance.sort(key=lambda x: x[1], reverse=True)
        
        print(f"\nğŸ“Š ìƒìœ„ 5ê°œ ì¤‘ìš” íŠ¹ì§•:")
        for i, (name, importance) in enumerate(feature_importance[:5], 1):
            print(f"   {i}. {name}: {importance:.4f}")
        
        return {
            'train_accuracy': train_acc,
            'test_accuracy': test_acc,
            'test_precision': test_precision,
            'test_recall': test_recall,
            'test_f1': test_f1,
            'confusion_matrix': cm,
            'feature_importance': feature_importance
        }
    
    def evaluate_on_data(self, df, window_size=3):
        """
        ì „ì²´ ë°ì´í„°ì— ëŒ€í•œ í‰ê°€
        
        Parameters:
        -----------
        df : pandas.DataFrame
            í‰ê°€ ë°ì´í„°
        window_size : int
            ìœˆë„ìš° í¬ê¸°
        """
        print("\n" + "="*70)
        print("ğŸ“Š ì „ì²´ ë°ì´í„° í‰ê°€")
        print("="*70)
        
        X, y = self.prepare_features(df, window_size)
        X_scaled = self.scaler.transform(X)
        
        predictions = self.model.predict(X_scaled)
        probabilities = self.model.predict_proba(X_scaled)[:, 1]
        
        accuracy = accuracy_score(y, predictions)
        precision = precision_score(y, predictions, zero_division=0)
        recall = recall_score(y, predictions, zero_division=0)
        f1 = f1_score(y, predictions, zero_division=0)
        
        print(f"\nâœ… í‰ê°€ ê²°ê³¼:")
        print(f"   ì •í™•ë„: {accuracy:.4f} ({accuracy*100:.2f}%)")
        print(f"   Precision: {precision:.4f} ({precision*100:.2f}%)")
        print(f"   Recall: {recall:.4f} ({recall*100:.2f}%)")
        print(f"   F1-Score: {f1:.4f} ({f1*100:.2f}%)")
        
        # Normal ìƒíƒœì—ì„œ High ìƒíƒœë¡œ ì „ì´ ì˜ˆì¸¡ ì„±ëŠ¥
        print(f"\nğŸ“Š Normal â†’ High ì „ì´ ì˜ˆì¸¡ ì„±ëŠ¥:")
        normal_indices = []
        for i in range(window_size, len(df) - 1):
            current_temp = df.iloc[i]['Temp_avg']
            current_co2 = df.iloc[i]['S5_CO2']
            if current_temp <= self.temp_threshold and current_co2 <= self.co2_threshold:
                normal_indices.append(i - window_size)
        
        if len(normal_indices) > 0:
            normal_y = y[normal_indices]
            normal_pred = predictions[normal_indices]
            normal_prob = probabilities[normal_indices]
            
            n2h_precision = precision_score(normal_y, normal_pred, zero_division=0)
            n2h_recall = recall_score(normal_y, normal_pred, zero_division=0)
            n2h_f1 = f1_score(normal_y, normal_pred, zero_division=0)
            
            print(f"   Normal ìƒíƒœ ì‚¬ë¡€ ìˆ˜: {len(normal_indices)}ê°œ")
            print(f"   ì‹¤ì œ Highë¡œ ì „ì´: {np.sum(normal_y)}ê°œ")
            print(f"   Precision: {n2h_precision:.4f} ({n2h_precision*100:.2f}%)")
            print(f"   Recall: {n2h_recall:.4f} ({n2h_recall*100:.2f}%)")
            print(f"   F1-Score: {n2h_f1:.4f} ({n2h_f1*100:.2f}%) â† í•µì‹¬ ì§€í‘œ")
        
        return {
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1': f1,
            'normal_to_high_f1': n2h_f1 if len(normal_indices) > 0 else 0,
            'predictions': predictions,
            'probabilities': probabilities
        }
    
    def visualize_feature_importance(self, save_path='feature_importance.png', top_n=10):
        """íŠ¹ì§• ì¤‘ìš”ë„ ì‹œê°í™”"""
        if self.model is None:
            print("ëª¨ë¸ì´ í•™ìŠµë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return
        
        feature_names = [
            'Temp_avg', 'S5_CO2', 'Temp_diff', 'CO2_Slope', 'Occupancy',
            'Dist_to_Temp_Thresh', 'Dist_to_CO2_Thresh',
            'Temp_Trend', 'CO2_Trend',
            'Temp_Avg_Recent', 'CO2_Avg_Recent',
            'Temp_Exceed', 'CO2_Exceed'
        ]
        
        importances = self.model.feature_importances_
        feature_importance = list(zip(feature_names, importances))
        feature_importance.sort(key=lambda x: x[1], reverse=True)
        
        top_features = feature_importance[:top_n]
        names, values = zip(*top_features)
        
        plt.figure(figsize=(10, 6))
        plt.barh(range(len(names)), values)
        plt.yticks(range(len(names)), names)
        plt.xlabel('Feature Importance')
        plt.title(f'Top {top_n} Feature Importance', fontsize=14, fontweight='bold')
        plt.gca().invert_yaxis()
        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"ğŸ“Š íŠ¹ì§• ì¤‘ìš”ë„ ì‹œê°í™” ì €ì¥: {save_path}")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ ê¸°ì¤€ì„  ì´ˆê³¼ íƒì§€ ëª¨ë¸ ì‹¤í–‰ ì‹œì‘")
    print("=" * 70)
    print("ğŸ’¡ ëª©ì : ë‹¤ìŒ ì‹œì ì— ê¸°ì¤€ì„ ì„ ë„˜ì„ì§€ ë¯¸ë¦¬ ì˜ˆì¸¡")
    print("ğŸ’¡ High ìƒíƒœ ì •ì˜: ì˜¨ë„ > 26Â°C AND CO2 > 1000ppm (ë‘˜ ë‹¤ ë„˜ì–´ì•¼ High)")
    print("=" * 70)
    
    # ë°ì´í„° ë¡œë“œ
    print("\nğŸ“‚ ë°ì´í„° ë¡œë“œ ì¤‘...")
    df = pd.read_csv('env_dataset_natural_oscillating.csv')
    df['Datetime'] = pd.to_datetime(df['Datetime'])
    print(f"ë°ì´í„° í¬ê¸°: {len(df)} í–‰")
    
    # ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
    print("\n" + "=" * 70)
    model = ThresholdDetectionModel(temp_threshold=26.0, co2_threshold=1000.0)
    results = model.fit(df, window_size=3)
    
    # íŠ¹ì§• ì¤‘ìš”ë„ ì‹œê°í™”
    model.visualize_feature_importance()
    
    # ì „ì²´ ë°ì´í„° í‰ê°€
    print("\n" + "=" * 70)
    eval_results = model.evaluate_on_data(df)
    
    # ìµœì¢… ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 70)
    print("âœ… ìµœì¢… ê²°ê³¼ ìš”ì•½")
    print("=" * 70)
    print(f"ì „ì²´ ì •í™•ë„: {eval_results['accuracy']:.4f} ({eval_results['accuracy']*100:.2f}%)")
    print(f"High ìƒíƒœ íƒì§€ F1-Score: {eval_results['f1']:.4f} ({eval_results['f1']*100:.2f}%)")
    print(f"Normalâ†’High ì „ì´ ì˜ˆì¸¡ F1-Score: {eval_results['normal_to_high_f1']:.4f} ({eval_results['normal_to_high_f1']*100:.2f}%) â† í•µì‹¬ ì§€í‘œ")
    
    if eval_results['normal_to_high_f1'] >= 0.5:
        print("âœ… ëª©í‘œ F1-Score 50% ì´ìƒ ë‹¬ì„±!")
    else:
        print("âš ï¸  ëª©í‘œ F1-Score 50% ë¯¸ë‹¬")
    
    return model, results, eval_results


if __name__ == '__main__':
    model, results, eval_results = main()
